# SketchySkills - Project Status

**Generated:** 2026-02-13 11:20 AM
**Phase:** Initial Setup (Day 1)

---

## âœ… Completed

### Project Structure
- [x] Git repo initialized
- [x] Directory structure created (`scanner/`, `dashboard/`, `data/`, `docs/`)
- [x] `.gitignore` configured

### Scanner Pipeline
- [x] `package.json` created
- [x] `fetch-skills.js` skeleton (downloads from ClawHub)
- [x] `analyze.js` skeleton (Opus 4.6 analysis)
- [x] `score.js` skeleton (calculate sketchy scores)
- [x] Analysis prompt template written (`prompts/skill-analysis-prompt.md`)
- [x] Dependencies installed (`glob` for file operations)

### Documentation
- [x] `README.md` (project overview)
- [x] `docs/METHODOLOGY.md` (detection patterns, scoring algorithm)
- [x] `docs/DEVELOPMENT.md` (setup guide, deployment instructions)

### Configuration
- [x] Added Opus 4.6 to OpenClaw config (`anthropic/claude-opus-4-6`)
- [x] Config backup created before modification

### Dashboard
- [ ] Next.js 15 installation in progress...

---

## ðŸš§ In Progress

- **Next.js Dashboard:** Running `create-next-app` (estimated 2-3 min)

---

## â¬œ TODO (Next Steps)

### Phase 1: Core Functionality

1. **Implement Fetch Script**
   - Parse ClawHub search output
   - Download all skills via CLI
   - Handle pagination (if >100 skills)
   - Store metadata JSON

2. **Implement Analysis Engine**
   - Load skill files
   - Format analysis prompt
   - Call Opus 4.6 (via OpenClaw sub-agent or API)
   - Parse JSON responses
   - Handle errors gracefully

3. **Implement Scoring Algorithm**
   - Weight findings by severity
   - Calculate 0-100 sketchy score
   - Classify into tiers
   - Generate public dashboard JSON

4. **Build Dashboard UI**
   - Home page (leaderboard table + charts)
   - Skill detail pages
   - About page
   - Responsive design + dark theme

5. **Test End-to-End**
   - Run scanner on sample skills
   - Verify Opus 4.6 access works
   - Validate scoring logic
   - Check dashboard renders correctly

### Phase 2: Deployment

6. **Set Up GitHub Repo**
   - Push to GitHub
   - Add LICENSE (MIT)
   - Write contributing guidelines

7. **Deploy to Vercel**
   - Connect GitHub repo
   - Configure build settings
   - Test live deployment

8. **Configure Automation**
   - Create OpenClaw cron job
   - Test daily scan workflow
   - Verify auto-deploy on push

### Phase 3: Launch

9. **Public Announcement**
   - Post to r/openclaw
   - Share in OpenClaw Discord
   - Tweet screenshot of top 10 sketchy skills

10. **Monitor & Iterate**
    - Track false positive reports
    - Tune detection patterns
    - Add historical trend tracking

---

## ðŸŽ¯ Current Focus

**Right now:** Waiting for Next.js installation to complete, then we'll:
1. Finish dashboard bootstrap
2. Implement the fetch script (get actual ClawHub data)
3. Test Opus 4.6 analysis on 2-3 sample skills

---

## ðŸ”¥ Blockers

### Opus 4.6 Access
**Status:** Unknown - need to test

When we tried to switch to Opus 4.6, got "Model not allowed" error. Possible causes:
- Anthropic API key doesn't have Opus access yet (preview period?)
- Missing config somewhere in OpenClaw
- Need to request access

**Mitigation:** For MVP, we can use Opus 4.6 via **isolated sub-agent sessions** in the scanner script. This bypasses session model restrictions and calls the API directly.

**Next action:** Test Opus 4.6 in a sub-agent spawn or via the OpenClaw API once we implement `analyze.js`.

---

## ðŸ’° Estimated Costs (First Scan)

Assuming ~700 skills on ClawHub:

**Opus 4.6 Pricing:**
- Input: $5 per million tokens
- Output: $25 per million tokens

**Per-skill estimate:**
- Average skill size: ~2K tokens (SKILL.md + files)
- Prompt overhead: ~1K tokens
- Total input per skill: ~3K tokens
- Expected output: ~500 tokens (JSON findings)

**Total for 700 skills:**
- Input: 700 Ã— 3K = 2.1M tokens = **$10.50**
- Output: 700 Ã— 500 = 350K tokens = **$8.75**
- **Total: ~$19.25 per full scan**

**Daily cost (after first scan):**
- Incremental scans only analyze new/updated skills
- Estimated: 10-20 skills/day = **$0.50-1.00/day**

**Monthly:** ~$20-30

---

## ðŸ“Š Success Metrics

**MVP Launch Criteria:**
- [x] Project structure complete
- [ ] Scanner can fetch all ClawHub skills
- [ ] Opus 4.6 analysis works on sample skills
- [ ] Dashboard displays results cleanly
- [ ] Deployed to public URL
- [ ] At least 1 critical skill detected

**Post-Launch Metrics:**
- Total skills scanned
- Critical/High severity count
- Community engagement (GitHub stars, Discord mentions)
- False positive rate (goal: <20%)

---

## ðŸ§€ Notes from Cheese

This is moving fast. We've got the skeleton done in ~1 hour. Key decisions made:

1. **Opus 4.6 via sub-agents:** Cleanest way to use it for analysis without session restrictions
2. **Static JSON dashboard:** No backend needed = free Vercel hosting
3. **Daily scans:** Balance between freshness and cost
4. **Conservative scoring:** False positives > false negatives for security

Next big milestone: **Get real ClawHub data and run first analysis.**

---

**Last Updated:** 2026-02-13 11:20 AM
